````
RocketMQ Broker中的消息被消费后会立即删除吗？
    不会，每条消息都会持久化到CommitLog中，每个Consumer连接到Broker后会维持消费进度信息，当有消息消费后只是当前Consumer的消费进度（CommitLog的offset）更新了。
    4.6版本默认48小时后会删除不再使用的CommitLog文件




RocketMQ消费模式有几种？
    消费模型由Consumer决定，消费维度为Topic。

    集群消费
        1.一条消息只会被同Group中的一个Consumer消费
        2.多个Group同时消费一个Topic时，每个Group都会有一个Consumer消费到数据
    广播消费 
        消息将对一 个Consumer Group 下的各个 Consumer 实例都消费一遍。即使这些 Consumer 属于同一个Consumer Group ，消息也会被 Consumer Group 中的每个 Consumer 都消费一次。 




消费消息是push还是pull？
    RocketMQ没有真正意义的push，都是pull，虽然有push类，但实际底层实现采用的是长轮询机制，即拉取方式 `broker端属性 longPollingEnable 标记是否开启长轮询。默认开启`
    
    为什么要主动拉取消息而不使用事件监听方式？
        如果broker主动推送消息的话有可能push速度快，消费速度慢的情况，那么就会造成消息在consumer端堆积过多，同时又不能被其他consumer消费的情况。而pull的方式可以根据当前自身情况来pull，
        不会造成过多的压力而造成瓶颈。所以采取了pull的方式。



消息重复消费造成的原因及解决办法(幂等性)?
    引起重复消费的原因
        - ACK: 正常情况下在consumer真正消费完消息后应该发送ack，通知broker该消息已正常消费，从queue中剔除, 当ack因为网络原因无法发送到broker，broker会认为词条消息没有被消费，此后会开启消息重投机制把消息再次投递到consumer
        - 消费模式: 在CLUSTERING模式下，消息在broker中会保证相同group的consumer消费一次，但是针对不同group的consumer会推送多次
    解决办法:
        - 数据库表: 处理消息前，使用消息主键在表中带有约束的字段中insert
        - Map: 单机时可以使用map ConcurrentHashMap -> putIfAbsent   guava cache
        - Redis: 利用分布式锁




如何让RocketMQ保证消息的顺序消费?
    首先多个queue只能保证单个queue里的顺序，queue是典型的FIFO，天然顺序, 索引可以将消息插入到指定 queue 中





如何保证RocketMQ消息不丢失:
    首先在如下三个部分都可能会出现丢失消息的情况：
        - Producer端
        - Broker端
        - Consumer端

    Producer端如何保证消息不丢失:
        - 采取send()同步发消息，发送结果是同步感知的 / 开启 RabbitMQ 事务（同步不推荐）
        - 发送失败后可以重试，设置重试次数。默认3次。

    Broker端如何保证消息不丢失:
        - 修改刷盘策略为同步刷盘。默认情况下是异步刷盘的(flushDiskType = SYNC_FLUSH)
        - 集群部署，主从模式，高可用。

    Consumer端如何保证消息不丢失   
        - 完全消费正常后在进行手动ack确认。





rocketMQ的消息堆积如何处理:
    首先要找到是什么原因导致的消息堆积，是Producer太多了，Consumer太少了导致的还是说其他情况，总之先定位问题。
    然后看下消息消费速度是否正常，正常的话，可以通过上线更多consumer临时解决消息堆积问题

    堆积时间过长消息超时了？
       RocketMQ中的消息只会在commitLog被删除的时候才会消失，不会超时。也就是说未被消费的消息不会存在超时删除这情况。

    堆积的消息会不会进死信队列？
        不会，消息在消费失败后会进入重试队列（%RETRY%+ConsumerGroup），18次（默认18次，网上所有文章都说是16次，无一例外。但是我没搞懂为啥是16次，这不是18个时间吗 ？）才会进入死信队列（%DLQ%+ConsumerGroup）。
        源码如下：
        public class MessageStoreConfig {
            // 每隔如下时间会进行重试，到最后一次时间重试失败的话就进入死信队列了。
            private String messageDelayLevel = "1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h";
        }
  

高吞吐量下如何优化生产者和消费者的性能?
    - 同一group下，多机部署，并行消费
    - 单个Consumer提高消费线程个数
    - 批量消费
        - 消息批量拉取
        - 业务逻辑批量处理



Broker把自己的信息注册到哪个NameServer上？
    Broker会向所有的NameServer上注册自己的信息，而不是某一个，是每一个，全部！
    
    
  
  
    
RocketMQ 如何保证高可用的？
    - 多 Master 模式：该模式下必须设置为异步复制，因为没有 Slave，异步刷盘会丢失部分数据，同步刷盘不会丢失数据；如果有一台 Master Broker 宕机，那么其上的消息在服务恢复前不会推送给消费端，会对消息实时性造成影响。
    - 多 Master 多 Slave 模式（异步复制）：异步复制的模式下在 Master 宕机、磁盘损坏等情况下会造成数据部分丢失；但是消费端仍然可以从 Slave 拉取消息，所以消息的实时性不受影响。
    - 多 Master 多 Slave 模式（同步双写）：同步复制同步刷盘会导致整体性能比异步模式低一些，发送单个消息的 RT 也会变高，但是服务可用性和数据可用性都很高而且消息实时性不受影响。





如何解决消息队列的延时以及过期失效问题？
    当消费端宕机或者消费速度很慢导致 Broker 中消息大量积压，如有积压时长超过阈值就会被清理掉导致数据丢失。

    RocketMQ 会把消息持久化到 CommitLog 文件里面，并且在以下的几种情况下会定期清理 CommitLog 文件：

    CommitLog 文件里面的消息积压超过了 72 小时，并且到了凌晨 4 点，清理线程会删除该文件；
    CommitLog 文件里面的消息积压超过了 72 小时，并且磁盘占用率达到了 75%，清理线程也会删除该文件；
    磁盘占用率达到了 85%，不管积压的消息是否过期都会触发线程批量清理文件，直到内存充足；
    磁盘占用率达到了 90%，Broker 出于保护自身的目的将会拒绝新发送的消息。
    出现消息积压并且过期失效问题，会导致这部分消息丢失，可以写一段程序找到丢失的消息，然后等到凌晨用户都休息的时候，这个时候系统负载比较低，再把丢失的这部分消息重新发送到 Broker 中。





消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？ 
    创建一个 Topic 并且把积压消息的 Topic 下的分区中的消息分发到新建的那个 Topic 中的更多分区中，新建 Topic 的分区数是积压消息的 Topic 的分区的 10 倍（具体多少分区根据具体业务场景决定）。
    积压的消息分发完以后停掉旧的消费端实例。
    每一个新建 Topic 的分区都对应启动一个消费端实例。
    积压的消息都消费完后，再把旧的消费端实例恢复    
````
